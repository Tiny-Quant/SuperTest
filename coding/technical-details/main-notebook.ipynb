{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric as pyg\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainee Model\n",
    "\n",
    "Reference: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data. \n",
    "from torch_geometric.datasets import TUDataset\n",
    "data_raw = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "# Shuffle.\n",
    "data_raw = data_raw.shuffle()\n",
    "\n",
    "# Split.\n",
    "train_data = data_raw[:150]\n",
    "test_data = data_raw[150:]\n",
    "\n",
    "# Create data lists.\n",
    "train_data_list = []\n",
    "train_data_list_0 = []\n",
    "train_data_list_1 = []\n",
    "test_data_list = []\n",
    "test_data_list_0 = []\n",
    "test_data_list_1 = []\n",
    "\n",
    "for graph in train_data:\n",
    "    train_data_list.append(graph)\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        train_data_list_0.append(graph)\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        train_data_list_1.append(graph)\n",
    "\n",
    "for graph in test_data:\n",
    "    test_data_list.append(graph)\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        test_data_list_0.append(graph)\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        test_data_list_1.append(graph)\n",
    "\n",
    "# Create data loaders.\n",
    "train_loader = pyg.loader.DataLoader(train_data_list, batch_size=64, shuffle=True)\n",
    "test_loader = pyg.loader.DataLoader(test_data_list, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padded dataset. \n",
    "max_num_nodes = 30 # 28 in the full dataset.  \n",
    "\n",
    "# ChatGPT: zero pad torch geometric data so every graph has the same number \n",
    "#          of nodes.\n",
    "# Edited\n",
    "def pad_graph(data, max_num_nodes):\n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # Pad node features\n",
    "    padded_x = torch.zeros((max_num_nodes, data.x.size(1)))\n",
    "    padded_x[:num_nodes] = data.x\n",
    "    \n",
    "    # Create padded adjacency matrix\n",
    "    padded_adj = torch.zeros((max_num_nodes, max_num_nodes))\n",
    "    padded_adj[:num_nodes, :num_nodes] = (\n",
    "        pyg.utils.to_dense_adj(data.edge_index).squeeze(0)\n",
    "    )\n",
    "    \n",
    "    # Create edge index from padded adjacency matrix\n",
    "    padded_edge_index = pyg.utils.dense_to_sparse(padded_adj)[0]\n",
    "    \n",
    "    # Create new data object with padded features\n",
    "    padded_data = pyg.data.Data(x=padded_x, edge_index=padded_edge_index,\n",
    "                                y=data.y)\n",
    "    \n",
    "    return padded_data\n",
    "\n",
    "# Create padded data lists.\n",
    "train_data_list_padded = []\n",
    "train_data_list_0_padded = []\n",
    "train_data_list_1_padded = []\n",
    "test_data_list_padded= []\n",
    "test_data_list_0_padded = []\n",
    "test_data_list_1_padded = []\n",
    "\n",
    "for graph in train_data:\n",
    "    train_data_list.append(pad_graph(graph, max_num_nodes))\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        train_data_list_0.append(pad_graph(graph, max_num_nodes))\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        train_data_list_1.append(pad_graph(graph, max_num_nodes))\n",
    "\n",
    "for graph in test_data:\n",
    "    test_data_list.append(pad_graph(graph, max_num_nodes))\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        test_data_list_0.append(pad_graph(graph, max_num_nodes))\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        test_data_list_1.append(pad_graph(graph, max_num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainee GNN Model \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = pyg.nn.GCNConv(7, hidden_channels) # 7 node features.\n",
    "        self.conv2 = pyg.nn.GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = pyg.nn.GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, 2) # 2 classes.\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # 1. Node embeddings.\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Pooling.\n",
    "        x = pyg.nn.global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. Prediction.\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 2 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 3 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 4 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 5 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 6 Train Accuracy: 0.7133333333333334 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 7 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.6052631578947368\n",
      "Epoch: 8 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.6052631578947368\n",
      "Epoch: 9 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.6052631578947368\n",
      "Epoch: 10 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 11 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 12 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 13 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 14 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 15 Train Accuracy: 0.76 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 16 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 17 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 18 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 19 Train Accuracy: 0.78 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 20 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 21 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 22 Train Accuracy: 0.78 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 23 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 24 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 25 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 26 Train Accuracy: 0.76 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 27 Train Accuracy: 0.76 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 28 Train Accuracy: 0.78 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 29 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 30 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 31 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 32 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 33 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 34 Train Accuracy: 0.76 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 35 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 36 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 37 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 38 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 39 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 40 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 41 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 42 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 43 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 44 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 45 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 46 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 47 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 48 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 49 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 50 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 51 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 52 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 53 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 54 Train Accuracy: 0.78 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 55 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 56 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 57 Train Accuracy: 0.8 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 58 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 59 Train Accuracy: 0.76 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 60 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 61 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 62 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 63 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 64 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 65 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 66 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 67 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 68 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 69 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 70 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 71 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 72 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 73 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 74 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 75 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 76 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 77 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 78 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 79 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 80 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 81 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 82 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 83 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 84 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 85 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 86 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 87 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 88 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 89 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 90 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 91 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 92 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 93 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 94 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 95 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 96 Train Accuracy: 0.8 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 97 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 98 Train Accuracy: 0.8 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 99 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 100 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 101 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 102 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 103 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 104 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 105 Train Accuracy: 0.8 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 106 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 107 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 108 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 109 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 110 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 111 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 112 Train Accuracy: 0.8 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 113 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 114 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 115 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 116 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 117 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 118 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 119 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 120 Train Accuracy: 0.8 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 121 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 122 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 123 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 124 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 125 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 126 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 127 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 128 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 129 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 130 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 131 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 132 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 133 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 134 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 135 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 136 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 137 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 138 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 139 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 140 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 141 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 142 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 143 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 144 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 145 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 146 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 147 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 148 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 149 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 150 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 151 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 152 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 153 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 154 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 155 Train Accuracy: 0.82 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 156 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 157 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 158 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 159 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 160 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 161 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 162 Train Accuracy: 0.82 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 163 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 164 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 165 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 166 Train Accuracy: 0.82 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 167 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 168 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 169 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 170 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "# Training Explainee.\n",
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(data_loader): \n",
    "    model.train()\n",
    "\n",
    "    for batch in data_loader: \n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def model_accuracy(data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for batch in data_loader: \n",
    "        out = model(batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == batch.y).sum())\n",
    "\n",
    "    return correct / len(data_loader.dataset)\n",
    "\n",
    "for epoch in range(1, 171): \n",
    "    train(train_loader)\n",
    "    train_accuracy = model_accuracy(train_loader)\n",
    "    test_accuracy = model_accuracy(test_loader)\n",
    "\n",
    "    print(f\"Epoch: {epoch} Train Accuracy: {train_accuracy} \" + \n",
    "          f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37,  26],\n",
       "       [ 10, 115]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "full_batch = pyg.data.Batch.from_data_list(test_data_list + train_data_list)\n",
    "model.eval()\n",
    "preds = model(full_batch).argmax(dim=1).numpy()\n",
    "targets = full_batch.y.numpy()\n",
    "\n",
    "conf_matrix = confusion_matrix(targets, preds)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "betas = []\n",
    "\n",
    "for batch in loader:\n",
    "    adj_batch = func(batch)\n",
    "    t ~ U[1, 50]\n",
    "    noised_adj = func(adj_batch)\n",
    "\n",
    "    pred_adj = model(noised_adj, t)\n",
    "\n",
    "    CrtEnt(adj_batch, pred_adj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "\n",
    "betas = torch.linspace(start=0.001, end=0.1, steps=T)\n",
    "beta_bars = []\n",
    "cum_prod = 1\n",
    "\n",
    "for beta in betas:\n",
    "    cum_prod *= (1 - 2*beta)\n",
    "    beta_bars.append(0.5 - 0.5 * cum_prod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_tensors(graphs: pyg.data.Batch, \n",
    "                     max_num_nodes=None) -> List[torch.tensor]:\n",
    "    # [b, n, n]\n",
    "    adj_batch = pyg.utils.to_dense_adj(graphs.edge_index, batch=graphs.batch, \n",
    "                                       max_num_nodes=max_num_nodes,\n",
    "                                       edge_attr = graphs.edge_attr)\n",
    "    # D4 uses the mask somehow.\n",
    "    x_batch, node_feat_mask = pyg.utils.to_dense_batch(graphs.x, graphs.batch, \n",
    "                                       max_num_nodes=max_num_nodes)    \n",
    "    return [adj_batch, x_batch, node_feat_mask]\n",
    "\n",
    "def forward_diffusion_sample(adj_batch: torch.tensor, t: int) -> torch.tensor:\n",
    "    transition_probs = torch.full_like(adj_batch, beta_bars[t])\n",
    "\n",
    "    # Symmetrically applies noise - treats edges as undirected.\n",
    "    noise_upper = torch.bernoulli(transition_probs).triu(diagonal=1)\n",
    "    noise_lower = noise_upper.transpose(-1, -2)\n",
    "    noised_adj_batch = torch.abs(adj_batch + noise_upper + noise_lower)\n",
    "\n",
    "    return noised_adj_batch\n",
    "\n",
    "class denoising_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(denoising_model, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(node_features: torch.tensor, \n",
    "                noised_adj_batch: torch.tensor, t: int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        node_features: [b, n, f].\n",
    "        noised_adj_batch: [b, n, n].\n",
    "        returns: [b, n, n] predicted adj.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6762.)\n",
      "tensor(6762.)\n"
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "low_noise = 0.0\n",
    "high_noise = 0.5\n",
    "noise_list = list(np.random.uniform(low=low_noise, high=high_noise, size=T))\n",
    "\n",
    "# Bernoulli distribution for the probability of an edge existing.\n",
    "bernoulli_adj = torch.full_like(x[1], noise_list[0])\n",
    "\n",
    "# Symmetrically applies noise - treats edges as undirected.\n",
    "noise_upper = torch.bernoulli(bernoulli_adj).triu(diagonal=1)\n",
    "noise_lower = noise_upper.transpose(-1, -2)\n",
    "train_adj = torch.abs(-x[1] + noise_upper + noise_lower)\n",
    "\n",
    "noisediff = noise_upper + noise_lower # record true noise. \n",
    "\n",
    "print((train_adj - x[1]).abs().sum())\n",
    "print(noisediff.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_half = x[1] > 1 / 2\n",
    "x_1 = x[1] >= 1\n",
    "torch.allclose(x_half, x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 30, 30, 4]) torch.Size([2, 30, 7]) torch.Size([2, 30])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dense adjacency matrix 'adj' must be two- or three-dimensional (got 4 dimensions)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[170], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m torch\u001b[38;5;241m.\u001b[39mallclose(adj_batch_1, adj_batch_2)\n\u001b[0;32m     17\u001b[0m batch\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 19\u001b[0m \u001b[43mpyg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_to_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\SuperTest2\\lib\\site-packages\\torch_geometric\\utils\\sparse.py:69\u001b[0m, in \u001b[0;36mdense_to_sparse\u001b[1;34m(adj, mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a dense adjacency matrix to a sparse adjacency matrix defined\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mby edge indices and edge attributes.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    tensor([3, 1, 2, 1, 2, 3, 5]))\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adj\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m adj\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDense adjacency matrix \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be two- or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthree-dimensional (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madj\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m adj\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     73\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask should not be provided in case the dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjacency matrix is two-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Dense adjacency matrix 'adj' must be two- or three-dimensional (got 4 dimensions)"
     ]
    }
   ],
   "source": [
    "# Manual training step.\n",
    "\n",
    "batch = pyg.data.Batch.from_data_list(train_data_list[:2])\n",
    "\n",
    "adj_batch, x_batch, node_feat_mask = graph_to_tensors(\n",
    "    batch, max_num_nodes)\n",
    "\n",
    "print(adj_batch.shape, x_batch.shape, node_feat_mask.shape)\n",
    "\n",
    "adj_batch_1 = adj_batch[:, :, :, 0] \n",
    "adj_batch_1\n",
    "\n",
    "adj_batch_2 = pyg.utils.to_dense_adj(\n",
    "    batch.edge_index, batch=batch.batch, max_num_nodes=max_num_nodes\n",
    ")\n",
    "torch.allclose(adj_batch_1, adj_batch_2)\n",
    "batch.edge_attr.shape\n",
    "\n",
    "pyg.utils.dense_to_sparse(adj_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "max_obs_nodes = 0\n",
    "for graph in train_data_list + test_data_list:\n",
    "    if graph.x.shape[0] > max_obs_nodes:\n",
    "        max_obs_nodes = graph.x.shape[0]\n",
    "\n",
    "print(max_obs_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
