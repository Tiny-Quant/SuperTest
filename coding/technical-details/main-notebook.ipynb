{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric as pyg\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainee Model\n",
    "\n",
    "Reference: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data. \n",
    "from torch_geometric.datasets import TUDataset\n",
    "data_raw = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "# Shuffle.\n",
    "data_raw = data_raw.shuffle()\n",
    "\n",
    "# Split.\n",
    "train_data = data_raw[:150]\n",
    "test_data = data_raw[150:]\n",
    "\n",
    "# Create data lists.\n",
    "train_data_list = []\n",
    "train_data_list_0 = []\n",
    "train_data_list_1 = []\n",
    "test_data_list = []\n",
    "test_data_list_0 = []\n",
    "test_data_list_1 = []\n",
    "\n",
    "for graph in train_data:\n",
    "    train_data_list.append(graph)\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        train_data_list_0.append(graph)\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        train_data_list_1.append(graph)\n",
    "\n",
    "for graph in test_data:\n",
    "    test_data_list.append(graph)\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        test_data_list_0.append(graph)\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        test_data_list_1.append(graph)\n",
    "\n",
    "# Create data loaders.\n",
    "train_loader = pyg.loader.DataLoader(train_data_list, batch_size=64, shuffle=True)\n",
    "test_loader = pyg.loader.DataLoader(test_data_list, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainee GNN Model \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = pyg.nn.GCNConv(7, hidden_channels) # 7 node features.\n",
    "        self.conv2 = pyg.nn.GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = pyg.nn.GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = nn.Linear(hidden_channels, 2) # 2 classes.\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # 1. Node embeddings.\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Pooling.\n",
    "        x = pyg.nn.global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. Prediction.\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 2 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 3 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 4 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 5 Train Accuracy: 0.7 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 6 Train Accuracy: 0.7133333333333334 Test Accuracy: 0.5263157894736842\n",
      "Epoch: 7 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.6052631578947368\n",
      "Epoch: 8 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.6052631578947368\n",
      "Epoch: 9 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.6052631578947368\n",
      "Epoch: 10 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 11 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 12 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 13 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 14 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 15 Train Accuracy: 0.76 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 16 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 17 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 18 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 19 Train Accuracy: 0.78 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 20 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 21 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 22 Train Accuracy: 0.78 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 23 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 24 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 25 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 26 Train Accuracy: 0.76 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 27 Train Accuracy: 0.76 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 28 Train Accuracy: 0.78 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 29 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 30 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 31 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 32 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 33 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 34 Train Accuracy: 0.76 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 35 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 36 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 37 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 38 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 39 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 40 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 41 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 42 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 43 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 44 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 45 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 46 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 47 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 48 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 49 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 50 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 51 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 52 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 53 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 54 Train Accuracy: 0.78 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 55 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 56 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 57 Train Accuracy: 0.8 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 58 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 59 Train Accuracy: 0.76 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 60 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 61 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 62 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 63 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 64 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 65 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 66 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 67 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 68 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 69 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 70 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 71 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 72 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 73 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 74 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 75 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 76 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 77 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 78 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 79 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 80 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 81 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 82 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 83 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 84 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 85 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 86 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 87 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 88 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 89 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 90 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 91 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 92 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 93 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 94 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 95 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 96 Train Accuracy: 0.8 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 97 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 98 Train Accuracy: 0.8 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 99 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 100 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 101 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 102 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 103 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 104 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 105 Train Accuracy: 0.8 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 106 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 107 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 108 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 109 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 110 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 111 Train Accuracy: 0.78 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 112 Train Accuracy: 0.8 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 113 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 114 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 115 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 116 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 117 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 118 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 119 Train Accuracy: 0.78 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 120 Train Accuracy: 0.8 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 121 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 122 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 123 Train Accuracy: 0.78 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 124 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 125 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 126 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 127 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 128 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 129 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 130 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 131 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 132 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 133 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 134 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 135 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 136 Train Accuracy: 0.7933333333333333 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 137 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 138 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 139 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 140 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 141 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 142 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 143 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 144 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 145 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 146 Train Accuracy: 0.82 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 147 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 148 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 149 Train Accuracy: 0.82 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 150 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 151 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 152 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 153 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 154 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 155 Train Accuracy: 0.82 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 156 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 157 Train Accuracy: 0.8066666666666666 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 158 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 159 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 160 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 161 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 162 Train Accuracy: 0.82 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 163 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 164 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 165 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 166 Train Accuracy: 0.82 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 167 Train Accuracy: 0.8266666666666667 Test Accuracy: 0.6578947368421053\n",
      "Epoch: 168 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.6842105263157895\n",
      "Epoch: 169 Train Accuracy: 0.8133333333333334 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 170 Train Accuracy: 0.8333333333333334 Test Accuracy: 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "# Training Explainee.\n",
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(data_loader): \n",
    "    model.train()\n",
    "\n",
    "    for batch in data_loader: \n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def model_accuracy(data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for batch in data_loader: \n",
    "        out = model(batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == batch.y).sum())\n",
    "\n",
    "    return correct / len(data_loader.dataset)\n",
    "\n",
    "for epoch in range(1, 171): \n",
    "    train(train_loader)\n",
    "    train_accuracy = model_accuracy(train_loader)\n",
    "    test_accuracy = model_accuracy(test_loader)\n",
    "\n",
    "    print(f\"Epoch: {epoch} Train Accuracy: {train_accuracy} \" + \n",
    "          f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37,  26],\n",
       "       [ 10, 115]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "full_batch = pyg.data.Batch.from_data_list(test_data_list + train_data_list)\n",
    "model.eval()\n",
    "preds = model(full_batch).argmax(dim=1).numpy()\n",
    "targets = full_batch.y.numpy()\n",
    "\n",
    "conf_matrix = confusion_matrix(targets, preds)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "betas = []\n",
    "\n",
    "for batch in loader:\n",
    "    adj_batch = func(batch)\n",
    "    t ~ U[1, 50]\n",
    "    noised_adj = func(adj_batch)\n",
    "\n",
    "    pred_adj = model(noised_adj, t)\n",
    "\n",
    "    CrtEnt(adj_batch, pred_adj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "\n",
    "betas = torch.linspace(start=0.001, end=0.1, steps=T)\n",
    "beta_bars = []\n",
    "cum_prod = 1\n",
    "\n",
    "for beta in betas:\n",
    "    cum_prod *= (1 - 2*beta)\n",
    "    beta_bars.append(0.5 - 0.5 * cum_prod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_adj_batch(graphs: pyg.data.Batch) -> List[torch.tensor]:\n",
    "    adj_batch = pyg.utils.to_dense_adj(graphs.edge_index, batch=graphs.batch)\n",
    "    return adj_batch\n",
    "\n",
    "def forward_diffusion_sample(adj_batch: torch.tensor, t: int) -> torch.tensor:\n",
    "    transition_probs = torch.full_like(adj_batch, beta_bars[t])\n",
    "\n",
    "    # Symmetrically applies noise - treats edges as undirected.\n",
    "    noise_upper = torch.bernoulli(transition_probs).triu(diagonal=1)\n",
    "    noise_lower = noise_upper.transpose(-1, -2)\n",
    "    noised_adj_batch = torch.abs(adj_batch + noise_upper + noise_lower)\n",
    "\n",
    "    return noised_adj_batch\n",
    "\n",
    "class denoising_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(denoising_model, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(node_features: torch.tensor, \n",
    "                noised_adj_batch: torch.tensor, t: int) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        node_features: [b, n, f]\n",
    "        noised_adj_batch: [b, n, n]\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6762.)\n",
      "tensor(6762.)\n"
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "low_noise = 0.0\n",
    "high_noise = 0.5\n",
    "noise_list = list(np.random.uniform(low=low_noise, high=high_noise, size=T))\n",
    "\n",
    "# Bernoulli distribution for the probability of an edge existing.\n",
    "bernoulli_adj = torch.full_like(x[1], noise_list[0])\n",
    "\n",
    "# Symmetrically applies noise - treats edges as undirected.\n",
    "noise_upper = torch.bernoulli(bernoulli_adj).triu(diagonal=1)\n",
    "noise_lower = noise_upper.transpose(-1, -2)\n",
    "train_adj = torch.abs(-x[1] + noise_upper + noise_lower)\n",
    "\n",
    "noisediff = noise_upper + noise_lower # record true noise. \n",
    "\n",
    "print((train_adj - x[1]).abs().sum())\n",
    "print(noisediff.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_half = x[1] > 1 / 2\n",
    "x_1 = x[1] >= 1\n",
    "torch.allclose(x_half, x_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
